# Second Brain - Environment Configuration Example
# Copy this file to .env.local and fill in your values

# Ollama Configuration (FREE local embeddings)
# Default: http://localhost:11434
OLLAMA_BASE=http://localhost:11434

# Embedding model to use (default: all-minilm)
# Pull the model with: ollama pull all-minilm
OLLAMA_EMBED_MODEL=all-minilm

# LLM model for question answering (default: llama3)
# Pull the model with: ollama pull llama3
OLLAMA_LLM_MODEL=llama3

# RAG Configuration
# Number of top chunks to retrieve (default: 5)
TOP_K=5

# Maximum characters for context (default: 3000)
MAX_CONTEXT_CHARS=3000
# Maximum embeddings to search (default: 1000)
# Lower = faster but may miss relevant results
# Higher = more thorough but slower
MAX_EMBEDDINGS_SEARCH=1000

# Database Configuration
# SQLite database path (absolute or relative)
DATABASE_URL=file:./prisma/data/app.db

# File Upload Configuration
# Directory where uploaded PDFs are stored
UPLOAD_DIR=./uploads
